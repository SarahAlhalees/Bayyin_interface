import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification
import torch
import numpy as np
import re
from collections import Counter

# -----------------------------------------
# Streamlit Page Settings
# -----------------------------------------
st.set_page_config(
Â  Â  page_title="Ø¨ÙÙŠÙÙ‘Ù†Ù’ - Ù…ØµÙ†Ù Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
Â  Â  page_icon="ğŸ“š",
Â  Â  layout="centered"
)

# -----------------------------------------
# Arabic text normalization
# -----------------------------------------
ARABIC_DIACRITICS = re.compile(r"[\u0617-\u061A\u064B-\u0652]")

def normalize_ar(text):
Â  Â  text = str(text)
Â  Â  text = ARABIC_DIACRITICS.sub("", text)
Â  Â  text = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", text)
Â  Â  text = re.sub(r"Ù‰", "ÙŠ", text)
Â  Â  text = re.sub(r"[Ø¤Ø¦]", "Ø¡", text)
Â  Â  text = re.sub(r"Ø©", "Ù‡", text)
Â  Â  text = re.sub(r"[^\w\s]", " ", text)
Â  Â  text = re.sub(r"\s+", " ", text).strip()
Â  Â  return text

# -----------------------------------------
# Load Models
# -----------------------------------------
@st.cache_resource
def load_models():
Â  Â  models = {}
Â  Â Â 
Â  Â  # Original Model: Arabertv2_D3Tok
Â  Â  try:
Â  Â  Â  Â  orig_repo = "SarahAlhalees/Arabertv2_D3Tok"
Â  Â  Â  Â  orig_subfolder = "Arabertv2_D3Tok"
Â  Â  Â  Â  models['orig_tokenizer'] = AutoTokenizer.from_pretrained(orig_repo, subfolder=orig_subfolder)
Â  Â  Â  Â  models['orig_model'] = AutoModelForSequenceClassification.from_pretrained(orig_repo, subfolder=orig_subfolder)
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ØµÙ„ÙŠ: {str(e)}")
Â  Â  Â  Â  models['orig_tokenizer'] = None
Â  Â  Â  Â  models['orig_model'] = None
Â  Â Â 
Â  Â  # Model 1: CAMeLBERTmix_D3Tok
Â  Â  try:
Â  Â  Â  Â  mix_repo = "SarahAlhalees/CAMeLBERTmix_D3Tok"
Â  Â  Â  Â  models['mix_tokenizer'] = AutoTokenizer.from_pretrained(mix_repo)
Â  Â  Â  Â  models['mix_model'] = BertForSequenceClassification.from_pretrained(mix_repo)
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ CAMeLBERTmix: {str(e)}")
Â  Â  Â  Â  models['mix_tokenizer'] = None
Â  Â  Â  Â  models['mix_model'] = None
Â  Â Â 
Â  Â  # Model 2: CAMeLBERTmsa_D3Tok
Â  Â  try:
Â  Â  Â  Â  msa_repo = "SarahAlhalees/CAMeLBERTmsa_D3Tok"
Â  Â  Â  Â  models['msa_tokenizer'] = AutoTokenizer.from_pretrained(msa_repo)
Â  Â  Â  Â  models['msa_model'] = BertForSequenceClassification.from_pretrained(msa_repo)
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ CAMeLBERTmsa: {str(e)}")
Â  Â  Â  Â  models['msa_tokenizer'] = None
Â  Â  Â  Â  models['msa_model'] = None
Â  Â Â 
Â  Â  return models

models_dict = load_models()
orig_tokenizer = models_dict.get('orig_tokenizer')
orig_model = models_dict.get('orig_model')
mix_tokenizer = models_dict.get('mix_tokenizer')
mix_model = models_dict.get('mix_model')
msa_tokenizer = models_dict.get('msa_tokenizer')
msa_model = models_dict.get('msa_model')

# -----------------------------------------
# UI Layout with Colorful Styling
# -----------------------------------------
st.markdown("""
Â  Â  <style>
Â  Â  textarea {
Â  Â  Â  Â  direction: rtl;
Â  Â  Â  Â  text-align: right;
Â  Â  Â  Â  font-size: 16px;
Â  Â  }
Â  Â  .rtl-text {
Â  Â  Â  Â  direction: rtl;
Â  Â  Â  Â  text-align: right;
Â  Â  }
Â  Â  .gradient-title {
Â  Â  Â  Â  background: linear-gradient(120deg, #667eea 0%, #764ba2 100%);
Â  Â  Â  Â  -webkit-background-clip: text;
Â  Â  Â  Â  -webkit-text-fill-color: transparent;
Â  Â  Â  Â  background-clip: text;
Â  Â  Â  Â  font-size: 3em;
Â  Â  Â  Â  font-weight: bold;
Â  Â  Â  Â  text-align: center;
Â  Â  }
Â  Â  .final-verdict-card {
Â  Â  Â  Â  background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
Â  Â  Â  Â  border-radius: 15px;
Â  Â  Â  Â  padding: 25px;
Â  Â  Â  Â  margin: 20px 0;
Â  Â  Â  Â  color: white;
Â  Â  Â  Â  text-align: center;
Â  Â  Â  Â  box-shadow: 0 10px 20px rgba(0,0,0,0.3);
Â  Â  Â  Â  border: 2px solid #fff;
Â  Â  }
Â  Â Â 
Â  Â  /* --- FIXED MODEL CARD CSS --- */
Â  Â  .model-card {
Â  Â  Â  Â  border-radius: 15px;
Â  Â  Â  Â  padding: 15px;
Â  Â  Â  Â  margin: 10px 0;
Â  Â  Â  Â  color: white;
Â  Â  Â  Â  box-shadow: 0 4px 8px rgba(0,0,0,0.1);
Â  Â  Â  Â  height: 220px; /* Fixed height for consistency */
Â  Â  Â  Â  display: flex;
Â  Â  Â  Â  flex-direction: column;
Â  Â  Â  Â  justify-content: center;
Â  Â  Â  Â  align-items: center;
Â  Â  }
Â  Â Â 
Â  Â  .model-card-orig { background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); color: white; }
Â  Â  .model-card-mix { background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; }
Â  Â  .model-card-msa { background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); color: white; }
Â  Â Â 
Â  Â  .level-badge {
Â  Â  Â  Â  display: inline-block;
Â  Â  Â  Â  padding: 8px 20px;
Â  Â  Â  Â  border-radius: 25px;
Â  Â  Â  Â  font-size: 1.2em;
Â  Â  Â  Â  font-weight: bold;
Â  Â  Â  Â  margin: 10px 0;
Â  Â  }
Â  Â  .level-1, .level-2 { background: #2ecc71; color: white; }
Â  Â  .level-3, .level-4 { background: #f39c12; color: white; }
Â  Â  .level-5, .level-6 { background: #e74c3c; color: white; }
Â  Â  </style>
""", unsafe_allow_html=True)

st.markdown("<h1 class='gradient-title'>Ø¨ÙÙŠÙÙ‘Ù†Ù’</h1>", unsafe_allow_html=True)
st.markdown("<h3 style='text-align: center; direction: rtl; color: #667eea;'>Ù…ØµÙ†Ù Ù…Ø³ØªÙˆÙ‰ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</h3>", unsafe_allow_html=True)

st.markdown("---")

text = st.text_area(
Â  Â  label="",
Â  Â  height=200,
Â  Â  placeholder="Ø§ÙƒØªØ¨ Ø£Ùˆ Ø§Ù„ØµÙ‚ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§...",
Â  Â  key="arabic_input"
)

# -----------------------------------------
# Prediction Logic
# -----------------------------------------
if st.button("ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Øµ", use_container_width=True):
Â  Â Â 
Â  Â  # 1. Check if text is empty
Â  Â  if not text.strip():
Â  Â  Â  Â  st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù‚Ø¨Ù„ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„ØªØµÙ†ÙŠÙ.")
Â  Â Â 
Â  Â  # 2. Check if text contains Arabic characters
Â  Â  # Uses Regex to look for characters in the Arabic Unicode block
Â  Â  elif not re.search(r'[\u0600-\u06ff]', text):
Â  Â  Â  Â  st.error("Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„ Ù„Ø§ ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ù‡ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ø¹Ø±Ø¨ÙŠ ØµØ­ÙŠØ­.")
Â  Â  Â  Â Â 
Â  Â  else:
Â  Â  Â  Â  # If checks pass, proceed with model logic
Â  Â  Â  Â  if not any([orig_model, mix_model, msa_model]):
Â  Â  Â  Â  Â  Â  st.error("Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  cleaned = normalize_ar(text)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  def predict_level(model, tokenizer, text_input):
Â  Â  Â  Â  Â  Â  Â  Â  if model and tokenizer:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  inputs = tokenizer(text_input, return_tensors="pt", truncation=True, padding=True, max_length=256)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with torch.no_grad():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logits = model(**inputs).logits
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  probs = torch.softmax(logits, dim=-1).numpy()[0]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pred_idx = np.argmax(probs)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  level = pred_idx + 1
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return level
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return None
Â  Â  Â  Â  Â  Â  Â  Â  return None

Â  Â  Â  Â  Â  Â  # Get predictions from all models
Â  Â  Â  Â  Â  Â  orig_level = predict_level(orig_model, orig_tokenizer, cleaned)
Â  Â  Â  Â  Â  Â  mix_level = predict_level(mix_model, mix_tokenizer, cleaned)
Â  Â  Â  Â  Â  Â  msa_level = predict_level(msa_model, msa_tokenizer, cleaned)

Â  Â  Â  Â  Â  Â  # -----------------------------------------
Â  Â  Â  Â  Â  Â  # Hard Voting Implementation
Â  Â  Â  Â  Â  Â  # -----------------------------------------
Â  Â  Â  Â  Â  Â  predictions = [l for l in [orig_level, mix_level, msa_level] if l is not None]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  final_level = None
Â  Â  Â  Â  Â  Â  if predictions:
Â  Â  Â  Â  Â  Â  Â  Â  # Find the most common element (Hard Voting)
Â  Â  Â  Â  Â  Â  Â  Â  counts = Counter(predictions)
Â  Â  Â  Â  Â  Â  Â  Â  final_level = counts.most_common(1)[0][0]

Â  Â  Â  Â  Â  Â  # -----------------------------------------
Â  Â  Â  Â  Â  Â  # Results Display
Â  Â  Â  Â  Â  Â  # -----------------------------------------
Â  Â  Â  Â  Â  Â  level_names = {
Â  Â  Â  Â  Â  Â  Â  Â  1: "Ø³Ù‡Ù„ Ø¬Ø¯Ø§Ù‹", 2: "Ø³Ù‡Ù„", 3: "Ù…ØªÙˆØ³Ø·",Â 
Â  Â  Â  Â  Â  Â  Â  Â  4: "ØµØ¹Ø¨ Ù‚Ù„ÙŠÙ„Ø§Ù‹", 5: "ØµØ¹Ø¨", 6: "ØµØ¹Ø¨ Ø¬Ø¯Ø§Ù‹"
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if final_level:
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  Â  Â  Â  Â  # Final Result (Hard Voting) Display
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"""
Â  Â  Â  Â  Â  Â  Â  Â  <div class='final-verdict-card'>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <h2 style='margin:0;'>Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©</h2>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <h1 style='font-size: 3.5em; margin: 10px 0;'>Ø§Ù„Ù…Ø³ØªÙˆÙ‰ {final_level}</h1>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <h3 style='opacity: 0.9;'>{level_names.get(final_level, '')}</h3>
Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  """, unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("<h4 style='text-align: right; direction: rtl; color: #555;'>ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:</h4>", unsafe_allow_html=True)

Â  Â  Â  Â  Â  Â  # Columns for individual models
Â  Â  Â  Â  Â  Â  c1, c2, c3 = st.columns(3)

Â  Â  Â  Â  Â  Â  def display_mini_card(column, title, level, css_class):
Â  Â  Â  Â  Â  Â  Â  Â  with column:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if level:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class='model-card {css_class}'>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <h4 style='margin-bottom:5px;'>{title}</h4>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class='level-badge level-{level}'>Ø§Ù„Ù…Ø³ØªÙˆÙ‰ {level}</div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <p style='margin-top:5px; font-weight:bold;'>{level_names.get(level)}</p>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  """, unsafe_allow_html=True)

Â  Â  Â  Â  Â  Â  display_mini_card(c1, "Arabertv2", orig_level, "model-card-orig")
Â  Â  Â  Â  Â  Â  display_mini_card(c2, "CAMeLBERT Mix", mix_level, "model-card-mix")
Â  Â  Â  Â  Â  Â  display_mini_card(c3, "CAMeLBERT MSA", msa_level, "model-card-msa")

# Footer
st.markdown("---")
st.markdown("<p style='text-align: center; color: #667eea;'>Â© 2025 â€” Ù…Ø´Ø±ÙˆØ¹ Ø¨ÙÙŠÙÙ‘Ù†Ù’</p>", unsafe_allow_html=True)
