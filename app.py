import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np
import re

# -----------------------------------------
# Streamlit Page Settings
# -----------------------------------------
st.set_page_config(
    page_title="Ø¨ÙÙŠÙ‘ÙÙ†Ù’",
    layout="centered"
)

# -----------------------------------------
# Arabic text normalization
# -----------------------------------------
ARABIC_DIACRITICS = re.compile(r"[\u0617-\u061A\u064B-\u0652]")

def normalize_ar(text):
    text = str(text)
    text = ARABIC_DIACRITICS.sub("", text)
    text = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", text)
    text = re.sub(r"Ù‰", "ÙŠ", text)
    text = re.sub(r"[Ø¤Ø¦]", "Ø¡", text)
    text = re.sub(r"Ø©", "Ù‡", text)
    text = re.sub(r"[^\w\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# -----------------------------------------
# Load Model
# -----------------------------------------
@st.cache_resource
def load_model():
    repo_id = "SarahAlhalees/Arabertv2_D3Tok"  # Just username/repo_name
    subfolder = "Arabertv2_D3Tok"  # The folder inside the repo
    tokenizer = AutoTokenizer.from_pretrained(repo_id, subfolder=subfolder)
    model = AutoModelForSequenceClassification.from_pretrained(repo_id, subfolder=subfolder)
    return tokenizer, model

tokenizer, model = load_model()

# -----------------------------------------
# UI Layout
# -----------------------------------------
st.title("Ø¨ÙÙŠÙ‘ÙÙ†Ù’")
st.markdown("""
### âœ¨ Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù„ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø³Ù‡ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡ØªÙ‡ 
""")
text = st.text_area(
    "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:",
    height=200,
    placeholder="Ø§ÙƒØªØ¨ Ù‡Ù†Ø§ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ‚ÙŠÙŠÙ… Ø³Ù‡ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡ØªÙ‡..."
)

# -----------------------------------------
# Prediction
# -----------------------------------------
if st.button("ğŸ” ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Øµ", use_container_width=True):
    if not text.strip():
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ.")
    else:
        cleaned = normalize_ar(text)

        inputs = tokenizer(
            cleaned,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=256
        )

        with torch.no_grad():
            logits = model(**inputs).logits

        probs = torch.softmax(logits, dim=-1).numpy()[0]
        pred_idx = np.argmax(probs)
        # Map to levels 1-6
        level = pred_idx + 1  # 0 â†’ 1, 5 â†’ 6

        st.success(f"ğŸ”¹ Ù…Ø³ØªÙˆÙ‰ Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©: **Ø§Ù„Ù…Ø³ØªÙˆÙ‰ {level}**")
        st.progress(int(probs[pred_idx] * 100))
        st.write(f"Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©: {probs[pred_idx]:.2%}")

        st.subheader("ğŸ”§ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
        st.write(cleaned)

# Footer
st.caption("Â© 2025 â€” Ù…Ø´Ø±ÙˆØ¹ Ø¨ÙÙŠÙ‘ÙÙ†Ù’ ")










